{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning - Ex.4\n",
    "\n",
    "Submitted by: [Osnat Haj Yahia]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\osnath\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi class classification \n",
    "\n",
    "In this exercise we will try to learn the DIGITS dataset. \n",
    "The dataset contains almost 2000 examples of hand written digits:\n",
    "$$y_i\\in\\{0,1,2,...,9\\}$$\n",
    "each sample is represented by a 64 features vector (bitmap of 8x8 pixels):\n",
    "$$x_i\\in R^{64}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n",
      "(1797,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAEICAYAAAByNDmmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa63c970>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "digits = datasets.load_digits() # load the dataset\n",
    "X = digits.data\n",
    "X = X/16\n",
    "y = digits.target\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "\n",
    "i = 47;\n",
    "plt.imshow(X[i,:].reshape(8,8),interpolation='nearest',cmap='gray')\n",
    "plt.title(y[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify '1' against the rest \n",
    "\n",
    "Use logistic regression to learn a classifier for the digit of '1' (y=1). Any other digits, should be classified by this model as '0'.\n",
    "\n",
    "Learn the model on 80% of the data and test it on the rest of the 20%. \n",
    "\n",
    "Count how many training examples and how many testing examples the model identified correctly and wrongly.\n",
    "\n",
    "Plot a few examples for each case (wrongly vs. correctly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAEICAYAAAByNDmmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa862cd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# your code here..\n",
    "#splitting the data 50/50\n",
    "x_trn = X[::2] # 0,2,4,6,...\n",
    "y_trn = y[::2]\n",
    "\n",
    "x_tst = X[1::2] # 1,3,5,7,...\n",
    "y_tst = y[1::2]\n",
    "\n",
    "#print(\"The digit that i want to predict is :\" + y_tst[47])\n",
    "\n",
    "#class k vs all\n",
    "def y_preprocess(y_trn, classifie_by):\n",
    "    y_trn_size = len(y_trn)\n",
    "    y = np.zeros(y_trn_size)\n",
    "    for i in range(y_trn_size): \n",
    "        if(y_trn[i] ==  classifie_by):\n",
    "            y[i] = 1\n",
    "        else:\n",
    "            y[i] = 0 \n",
    "    return y\n",
    "\n",
    "def calc_sigmoid(z):\n",
    "    sigmoid=1/(1 + np.exp(-z))\n",
    "    return sigmoid\n",
    "\n",
    "def calac_cost(x, y, w, N):\n",
    "    x_trans = x.transpose()\n",
    "    z = np.dot(w,x_trans)\n",
    "    y_hat = calc_sigmoid(z)\n",
    "    j = 1/N * sum(-y * np.log(y_hat) + (1 - y) * np.log(1 - y_hat)) \n",
    "    return j\n",
    "\n",
    "\n",
    "def gradient_descent (x, y , alpha ,number_of_iteration):\n",
    "    j = np.zeros(number_of_iteration) # to hold the cost function value J at each iteration\n",
    "    N,d = X.shape\n",
    "    w = np.zeros(d)\n",
    "\n",
    "    for i in range(number_of_iteration):\n",
    "        x_trans = x.transpose()\n",
    "        z= np.dot(w,x_trans)\n",
    "        y_hat = calc_sigmoid(z)\n",
    "        w = w - alpha * (np.dot(x_trans,y_hat - y))\n",
    "        j[i] = calac_cost(x, y, w, N)\n",
    "    return w,j\n",
    "    \n",
    "def predict(x,w):\n",
    "    x_trans = x.transpose()\n",
    "    z = np.dot(w,x_trans)\n",
    "    predection = calc_sigmoid(z)\n",
    "    return predection\n",
    "\n",
    "\n",
    "alpha = 0.00001\n",
    "number_of_iteration = 100000\n",
    "\n",
    "i = 49;\n",
    "plt.imshow(x_tst[i,:].reshape(8,8),interpolation='nearest',cmap='gray')\n",
    "plt.title(y_tst[49])\n",
    "plt.show()\n",
    "\n",
    "#class k vs all \n",
    "y_1 = y_preprocess(y_trn, classifie_by = 1)\n",
    "w,j = gradient_descent(x_trn, y_1 , alpha , number_of_iteration) \n",
    "f1 = predict(x_tst[47], w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify '2' against the rest, and so on..\n",
    "\n",
    "\n",
    "Continue and learn one classifier for each of the digits (0-9). Make sure that your algorithm converged in each one of them.\n",
    "\n",
    "Now that you have 10 binary classifiers, one for each digit, lets use them as a multi-class classifier. The multi-class classifier will return $y_i\\in\\{0,1,2,...,9\\}$ corresponding to the binary classifier with the highest output.\n",
    "\n",
    "Summarize your results on the (80%) training data and on the (20%) testing data using a *confusion matrix* $M$.\n",
    "\n",
    "Where $M_{i,j}$ counts how many examples with true label $y=i$ were classified as $j$.\n",
    "\n",
    "see also: <https://en.wikipedia.org/wiki/Confusion_matrix>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier for y = 0 : 2.62696203641e-06\n",
      "classifier for y = 1 : 0.784772975457\n",
      "classifier for y = 2 : 0.000207638292075\n",
      "classifier for y = 3 : 1.88137520317e-05\n",
      "classifier for y = 4 : 0.142559107637\n",
      "classifier for y = 5 : 0.000273285617189\n",
      "classifier for y = 6 : 0.00294090226258\n",
      "classifier for y = 7 : 0.000154798477603\n",
      "classifier for y = 8 : 0.00220952365523\n",
      "classifier for y = 9 : 1.07425457443e-05\n",
      "0.784772975457\n"
     ]
    }
   ],
   "source": [
    "y_2 = y_preprocess(y_trn, classifie_by = 2)\n",
    "w2,j2 = gradient_descent(x_trn, y_2 , alpha , number_of_iteration)\n",
    "f2 = predict(x_tst[49],w2)\n",
    "\n",
    "\n",
    "y_3 = y_preprocess(y_trn, classifie_by = 3)\n",
    "w3,j3 = gradient_descent(x_trn, y_3 , alpha , number_of_iteration)\n",
    "f3 = predict(x_tst[49],w3)\n",
    "\n",
    "\n",
    "y_4 = y_preprocess(y_trn, classifie_by = 4)\n",
    "w4,j4 = gradient_descent(x_trn, y_4 , alpha , number_of_iteration)\n",
    "f4 = predict(x_tst[49],w4)\n",
    "\n",
    "\n",
    "\n",
    "y_5 = y_preprocess(y_trn, classifie_by = 5)\n",
    "w5,j5 = gradient_descent(x_trn, y_5 , alpha , number_of_iteration)\n",
    "f5 = predict(x_tst[49],w5)\n",
    "\n",
    "\n",
    "\n",
    "y_6 = y_preprocess(y_trn, classifie_by = 6)\n",
    "w6,j6 = gradient_descent(x_trn, y_6 , alpha , number_of_iteration)\n",
    "f6 = predict(x_tst[49],w6)\n",
    "\n",
    "\n",
    "\n",
    "y_7 = y_preprocess(y_trn, classifie_by = 7)\n",
    "w7,j7 = gradient_descent(x_trn, y_7 , alpha , number_of_iteration)\n",
    "f7 = predict(x_tst[49],w7)\n",
    "\n",
    "\n",
    "\n",
    "y_8 = y_preprocess(y_trn, classifie_by = 8)\n",
    "w8,j8 = gradient_descent(x_trn, y_8 , alpha , number_of_iteration)\n",
    "f8 = predict(x_tst[49],w8)\n",
    "\n",
    "\n",
    "\n",
    "y_9 = y_preprocess(y_trn, classifie_by = 9)\n",
    "w9,j9 = gradient_descent(x_trn, y_9 , alpha , number_of_iteration)\n",
    "f9 = predict(x_tst[49],w9)\n",
    "\n",
    "\n",
    "\n",
    "y_0 = y_preprocess(y_trn, classifie_by = 0)\n",
    "w0,j0 = gradient_descent(x_trn, y_0 , alpha , number_of_iteration)\n",
    "f0 = predict(x_tst[49],w0)\n",
    "\n",
    "\n",
    "result = max(f1 ,f2 ,f3 ,f4, f5, f6, f7, f8, f9, f0)\n",
    "\n",
    "print('classifier for y = 0 :' , f0)\n",
    "print('classifier for y = 1 :' , f1)\n",
    "print('classifier for y = 2 :' , f2)\n",
    "print('classifier for y = 3 :' , f3)\n",
    "print('classifier for y = 4 :' , f4)\n",
    "print('classifier for y = 5 :' , f5)\n",
    "print('classifier for y = 6 :' , f6)\n",
    "print('classifier for y = 7 :' , f7)\n",
    "print('classifier for y = 8 :' , f8)\n",
    "print('classifier for y = 9 :' , f9)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Good luck !"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
